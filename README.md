# ğŸ¤– [Evaluating AI Agents](https://www.deeplearning.ai/short-courses/evaluating-ai-agents/)

Welcome to the "Evaluating AI Agents" course! ğŸ¯ This course, created in collaboration with **Arize AI** and taught by **John Gilhuly** (Head of Developer Relations) and **Aman Khan** (Director of Product), will equip you with practical skills to **systematically evaluate, debug, and improve AI agents** during development and deployment.

---

## ğŸ“˜ Course Summary
This course walks you through the essential tools and techniques to measure and iterate on AI agent performance. Youâ€™ll learn to evaluate agent behaviors step-by-step, select the right metrics and evaluators, and run structured experiments to optimize agent outcomes.

### **What Youâ€™ll Learn**
1. ğŸ” **Observability & Debugging**: Learn how to add tracing to your agents to visualize and debug their actions.
2. ğŸ§ª **Structured Evaluation**: Understand the differences between evaluating traditional software vs. LLM agents, and how to test individual agent components.
3. âš–ï¸ **Evaluator Selection**: Learn when to use code-based metrics, LLM-as-a-judge, or human annotations for reliable feedback.
4. ğŸ” **Running Experiments**: Conduct structured experiments by changing model parameters, prompts, or agent logic to iteratively improve performance.
5. ğŸ“Š **Component-Wise Evaluation**: Test agent submodules like skills and router decisions using real examples.
6. ğŸ“ˆ **Production Monitoring**: Deploy these evaluation techniques in production to ensure consistent agent performance over time.

---

## ğŸ”‘ Key Points
- ğŸ§  **Trace and Debug AI Agents**: Add observability to track decision-making steps and identify performance bottlenecks.
- âš™ï¸ **Use Evaluation Metrics Thoughtfully**: Apply convergence scores, response accuracy, and step efficiency to fine-tune your agent.
- ğŸ”¬ **Structured Experimentation**: Improve agents with a scientific, reproducible approach.

---

## ğŸ‘¨â€ğŸ« About the Instructors
**John Gilhuly**  
*Head of Developer Relations at Arize AI*  

**Aman Khan**  
*Director of Product at Arize AI*  

Both bring extensive experience in LLM observability, evaluation tooling, and production deployment of intelligent agents.

---

ğŸš€ **Start evaluating smarter AI agents today**:  
ğŸ“š [deeplearning.ai](https://www.deeplearning.ai/short-courses/)
